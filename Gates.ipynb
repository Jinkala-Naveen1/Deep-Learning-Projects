{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-kG9Ta-OPye",
        "outputId": "508f226b-b89a-41e8-ed5e-6fe997612ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated weights are: -0.39999999999999997 -0.09999999999999981\n",
            "Input: (0, 0,1.4)  Output: 1\n",
            "Input: (0, 1,1.4)  Output: 1\n",
            "Input: (1, 0,1.4)  Output: 1\n",
            "Input: (1, 1,1.4)  Output: 0\n"
          ]
        }
      ],
      "source": [
        "w1 = 0.4\n",
        "w2 = 1.9\n",
        "b = 0\n",
        "n = 0.2\n",
        "inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "desired_output = [1,1,1,0]\n",
        "\n",
        "def activation(w1, w2, x1, x2, b):\n",
        "    x = x1 * w1 + x2 * w2 + b\n",
        "    return 1 if x >= 1 else 0\n",
        "\n",
        "def perceptron():\n",
        "    global w1, w2, b\n",
        "    epochs = 100  # Limit the number of epochs to avoid infinite loops\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(inputs)):\n",
        "            x1, x2 = inputs[i]\n",
        "            output = activation(w1, w2, x1, x2, b)\n",
        "            error = desired_output[i] - output\n",
        "            if error != 0:\n",
        "                w1 += error * n * x1\n",
        "                w2 += error * n * x2\n",
        "                b += error * n\n",
        "                total_error += abs(error)\n",
        "        if total_error == 0:\n",
        "            break\n",
        "\n",
        "perceptron()\n",
        "print(\"Updated weights are:\", w1, w2)\n",
        "for i in range(len(inputs)):\n",
        "    x1, x2 = inputs[i]\n",
        "    output = activation(w1, w2, x1, x2, b)\n",
        "    print(f\"Input: ({x1}, {x2},{b})  Output: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xor gate using perceptron 2\n",
        "#https://www.geeksforgeeks.org/implementation-of-perceptron-algorithm-for-xor-logic-gate-with-2-bit-binary-input/\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def unitStep(v):\n",
        "    if v >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def perceptronModel(x, w, b):\n",
        "    v = np.dot(w, x) + b\n",
        "    y = unitStep(v)\n",
        "    return y\n",
        "\n",
        "def NOT_logicFunction(x):\n",
        "    wNOT = -1\n",
        "    bNOT = 0.5\n",
        "    return perceptronModel(x, wNOT, bNOT)\n",
        "\n",
        "def AND_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    bAND = -1.5\n",
        "    return perceptronModel(x, w, bAND)\n",
        "\n",
        "def OR_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    bOR = -0.5\n",
        "    return perceptronModel(x, w, bOR)\n",
        "\n",
        "def XOR_logicFunction(x):\n",
        "    y1 = AND_logicFunction(x)\n",
        "    y2 = OR_logicFunction(x)\n",
        "    y3 = NOT_logicFunction(y1)\n",
        "    final_x = np.array([y2, y3])\n",
        "    finalOutput = AND_logicFunction(final_x)\n",
        "    return finalOutput\n",
        "\n",
        "test1 = np.array([0, 0])\n",
        "test2 = np.array([0, 1])\n",
        "test3 = np.array([1, 0])\n",
        "test4 = np.array([1, 1])\n",
        "\n",
        "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test1)))\n",
        "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test2)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test3)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSMRDRCdWC0s",
        "outputId": "e165610d-4101-4be5-f40b-37d761160f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(0, 0) = 0\n",
            "XOR(0, 1) = 1\n",
            "XOR(1, 0) = 1\n",
            "XOR(1, 1) = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activate(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "def perceptron(inputs):\n",
        "    # Initialize weight and bias\n",
        "    w1, b = -1, 0\n",
        "    # Desired outputs for NOT gate\n",
        "    desired_outputs = [1, 0]\n",
        "    # Set learning rate and epochs\n",
        "    learning_rate = 0.1\n",
        "    epochs = 100\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(inputs)):\n",
        "            A = inputs[i]\n",
        "            target_output = desired_outputs[i]\n",
        "            output = activate(w1 * A + b)\n",
        "            error = target_output - output\n",
        "            # Update weight and bias\n",
        "            w1 += learning_rate * error * A\n",
        "            b += learning_rate * error\n",
        "            total_error += abs(error)\n",
        "        if total_error == 0:\n",
        "            break  # Stop if there are no errors\n",
        "\n",
        "    return w1, b\n",
        "\n",
        "inputs = [0, 1]\n",
        "w1, b = perceptron(inputs)\n",
        "\n",
        "for i in range(len(inputs)):\n",
        "    A = inputs[i]\n",
        "    output = activate(w1 * A + b)\n",
        "    print(f\"Input: {A}, Weight: {w1}, Bias: {b}, Output: {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6giVUXRcUBw",
        "outputId": "d8ce472e-8813-4b82-8358-094e9307f71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 0, Weight: -1.0, Bias: 0.0, Output: 1\n",
            "Input: 1, Weight: -1.0, Bias: 0.0, Output: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Adaline neural network\n",
        "def Adaline(Input, Target, lr=0.1):\n",
        "\tweight = np.random.random(Input.shape[1])\n",
        "\tbias = 0.1\n",
        "\terror=[]\n",
        "\tfor i in range(Input.shape[0]):\n",
        "\t\tY_input = sum(weight*Input[i]) + bias\n",
        "\t\tfor j in range(Input.shape[1]):\n",
        "\t\t\tweight[j]=weight[j] + lr*(Target[i]-Y_input)*Input[i][j]\n",
        "\n",
        "\t\t\t# Update the bias\n",
        "\t\tbias=bias + lr*(Target[i]-Y_input)\n",
        "\t\terror.append((Target[i]-Y_input)**2)\n",
        "\n",
        "\treturn weight, bias,error\n",
        "\n",
        "# Input dataset\n",
        "x = np.array([[1.0, 1.0],\n",
        "\t\t\t[1.0, -1.0],\n",
        "\t\t\t[-1.0, 1.0],\n",
        "\t\t\t[-1.0, -1.0]])\n",
        "# Target values\n",
        "t = np.array([1, 1, 1, -1])\n",
        "\n",
        "w,b,e = Adaline(x, t, lr=0.1)\n",
        "print('weight :',w)\n",
        "print('Bias :',b)\n",
        "print('error :',e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAgUazu2fZU-",
        "outputId": "c4b5b5fb-3d15-4f0b-b964-86c8048041f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight : [0.419506   0.21970428]\n",
            "Bias : 0.24213634851695653\n",
            "error : [0.2930250628295536, 0.24633482978873045, 1.550142664381385, 0.7418772415390222]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#madaline\n",
        "import numpy as np\n",
        "def activation(z):\n",
        "    if z>=0:\n",
        "        return 1\n",
        "    else:\n",
        "        return -1\n",
        "def madaline(input,target,lr,epoch):\n",
        "    #adaine weights and bias\n",
        "    weight=np.random.random((input.shape[1],input.shape[1]))\n",
        "    bias=np.random.random(input.shape[1])\n",
        "    w=np.array([0.5 for i in range(weight.shape[1])])#fixed weights and bias\n",
        "    b=0.5\n",
        "    k=0\n",
        "    while k<epoch:\n",
        "        error=[]\n",
        "        z_input=np.zeros(bias.shape[0])\n",
        "        z=np.zeros(bias.shape[0])\n",
        "        for i in range(input.shape[0]):\n",
        "            for j in range(input.shape[1]):\n",
        "                z_input[j]=sum(weight[j]*input[i])+bias[j]\n",
        "                z[j]=activation(z_input[j])\n",
        "            y_input=sum(z*w)+b\n",
        "            y=activation(y_input)\n",
        "            if y!=target[i]:\n",
        "                 for j in range(input.shape[1]):\n",
        "                     weight[j]+=lr*(target[i]-z_input[j])*input[i][j]\n",
        "                     bias=bias+lr*(target[i]-z_input[j])\n",
        "            error.append((target[i]-z_input[j])**2)\n",
        "        k+=1\n",
        "    return weight,bias\n",
        "x=np.array([[1,1],[1,-1],[-1,1],[-1,-1]])\n",
        "t=np.array([1,1,1,-1])\n",
        "w,b=madaline(x,t,0.1,3)\n",
        "print(\"weight:\",w)\n",
        "print(\"bias:\",b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU1ZYn_YgKJ6",
        "outputId": "727c9ec6-071b-4795-e50e-cade5de967f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: [[0.50260252 0.33057635]\n",
            " [0.72214963 0.97669826]]\n",
            "bias: [0.62934056 0.92200169]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMbEItImh8xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mE0mya9Rh8-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}